{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Header Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "emails, labels = [], []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Load"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "file_path = 'enron1/spam/'\n",
    "for filename in glob.glob(os.path.join(file_path, '*.txt')):\n",
    "    with open(filename, 'r', encoding = \"ISO-8859-1\") as infile:\n",
    "        emails.append(infile.read())\n",
    "        labels.append(1)\n",
    "\n",
    "file_path = 'enron1/ham/'\n",
    "for filename in glob.glob(os.path.join(file_path, '*.txt')):\n",
    "    with open(filename, 'r', encoding = \"ISO-8859-1\") as infile:\n",
    "        emails.append(infile.read())\n",
    "        labels.append(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Name Data Load"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "all_names = set(names.words())\n",
    "lemmatizer = WordNetLemmatizer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Clean Code Define"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def letters_only(astr):\n",
    "    for c in astr:\n",
    "        if not c.isalpha():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def clean_text(docs):\n",
    "    cleaned_docs = []\n",
    "    for doc in docs:\n",
    "        cleaned_docs.append(' '.join([lemmatizer.lemmatize(word.lower())\n",
    "                                      for word in doc.split()\n",
    "                                      if letters_only(word)\n",
    "                                      and word not in all_names]))\n",
    "    return cleaned_docs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "cleaned_emails = clean_text(emails)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# K-Fold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "k = 10\n",
    "k_fold = StratifiedKFold(n_splits=k)\n",
    "# convert to numpy array for more efficient slicing\n",
    "cleaned_emails_np = np.array(cleaned_emails)\n",
    "labels_np = np.array(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Smoothing Define"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "smoothing_factor_option = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "from collections import defaultdict\n",
    "auc_record = defaultdict(float)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Apply K-Fold and Smoothing\n",
    "\n",
    "## TfidfVectorizer\n",
    "- sublinear_tf : 빈도에 Log 함수를 씌워서 Smoothing\n",
    "- max_df : 문서의 빈도가 너무 높은 경우 상한선\n",
    "- stop_words : 불용어 사전\n",
    "- max_features : 해당 값 만큼의 단어를 선택"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "for train_indices, test_indices in k_fold.split(cleaned_emails, labels):\n",
    "    X_train, X_test = cleaned_emails_np[train_indices], cleaned_emails_np[test_indices]\n",
    "    Y_train, Y_test = labels_np[train_indices], labels_np[test_indices]\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english', max_features=8000)\n",
    "    term_docs_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "    term_docs_test = tfidf_vectorizer.transform(X_test)\n",
    "    for smoothing_factor in smoothing_factor_option:\n",
    "        clf = MultinomialNB(alpha=smoothing_factor, fit_prior=True)\n",
    "        clf.fit(term_docs_train, Y_train)\n",
    "        prediction_prob = clf.predict_proba(term_docs_test)\n",
    "        pos_prob = prediction_prob[:, 1]\n",
    "        auc = roc_auc_score(Y_test, pos_prob)\n",
    "        auc_record[smoothing_factor] += auc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'float'>, {1.0: 9.936995073648463, 2.0: 9.945108942463373, 3.0: 9.950318435809343, 4.0: 9.953585278205583, 5.0: 9.956125705880032})\n",
      "max features  smoothing  fit prior  auc\n",
      "       8000      1.0      true    0.9937\n",
      "       8000      2.0      true    0.9945\n",
      "       8000      3.0      true    0.9950\n",
      "       8000      4.0      true    0.9954\n",
      "       8000      5.0      true    0.9956\n"
     ]
    }
   ],
   "source": [
    "print(auc_record)\n",
    "\n",
    "print('max features  smoothing  fit prior  auc')\n",
    "for smoothing, smoothing_record in auc_record.items():\n",
    "    print('       8000      {0}      true    {1:.4f}'.format(smoothing, smoothing_record/k))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metric Result\n",
    "- TF-idf 를 적용하지 않은 roc-auc 의 결과 0.9856 의 결과보다 높은 0.9956이 나왔다."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}